{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data ingestion from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_data(api_url):\n",
    "    response = requests.get(api_url)\n",
    "    genre_data = response.json()\n",
    "    return genre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_data(api_url):\n",
    "    all_movie_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(api_url, params={'page': page})\n",
    "        movie_data = response.json()\n",
    "\n",
    "        if not movie_data or not movie_data['results']:\n",
    "            break\n",
    "        else:\n",
    "            for single_movie in movie_data['results']:\n",
    "                movie_details = {}\n",
    "                movie_details['title'] = single_movie['title']\n",
    "                movie_details['overview'] = single_movie['overview']\n",
    "                movie_details['genres'] =', '.join([movie_genres.get(genre_id) for genre_id in single_movie['genre_ids']])\n",
    "                movie_details['popularity'] = single_movie['popularity']\n",
    "                all_movie_data.append(movie_details)\n",
    "            page += 1\n",
    "    \n",
    "    return all_movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch movie genre data from API\n",
    "genre_api_url = 'https://api.themoviedb.org/3/genre/movie/list?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{28: 'Action',\n",
       " 12: 'Adventure',\n",
       " 16: 'Animation',\n",
       " 35: 'Comedy',\n",
       " 80: 'Crime',\n",
       " 99: 'Documentary',\n",
       " 18: 'Drama',\n",
       " 10751: 'Family',\n",
       " 14: 'Fantasy',\n",
       " 36: 'History',\n",
       " 27: 'Horror',\n",
       " 10402: 'Music',\n",
       " 9648: 'Mystery',\n",
       " 10749: 'Romance',\n",
       " 878: 'Science Fiction',\n",
       " 10770: 'TV Movie',\n",
       " 53: 'Thriller',\n",
       " 10752: 'War',\n",
       " 37: 'Western'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_data = get_genre_data(genre_api_url)\n",
    "genre_list = genre_data['genres']\n",
    "movie_genres = { genre['id']: genre['name'] for genre in genre_list}\n",
    "movie_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch movie data from API\n",
    "movie_api_url = 'https://api.themoviedb.org/3/movie/top_rated?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US&page=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = get_movie_data(movie_api_url)\n",
    "movie_data = pd.DataFrame(movie_data)\n",
    "movie_data.to_csv('artifacts/movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "      <td>Drama, Crime</td>\n",
       "      <td>146.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>Drama, Crime</td>\n",
       "      <td>121.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>Drama, Crime</td>\n",
       "      <td>82.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>Drama, History, War</td>\n",
       "      <td>66.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>The defense and the prosecution have rested an...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>59.231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  The Shawshank Redemption   \n",
       "1             The Godfather   \n",
       "2     The Godfather Part II   \n",
       "3          Schindler's List   \n",
       "4              12 Angry Men   \n",
       "\n",
       "                                            overview               genres  \\\n",
       "0  Framed in the 1940s for the double murder of h...         Drama, Crime   \n",
       "1  Spanning the years 1945 to 1955, a chronicle o...         Drama, Crime   \n",
       "2  In the continuing saga of the Corleone crime f...         Drama, Crime   \n",
       "3  The true story of how businessman Oskar Schind...  Drama, History, War   \n",
       "4  The defense and the prosecution have rested an...                Drama   \n",
       "\n",
       "   popularity  \n",
       "0     146.944  \n",
       "1     121.870  \n",
       "2      82.270  \n",
       "3      66.670  \n",
       "4      59.231  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('artifacts/movie_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9101, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9101 entries, 0 to 9100\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   title       9101 non-null   object \n",
      " 1   overview    9100 non-null   object \n",
      " 2   genres      9100 non-null   object \n",
      " 3   popularity  9101 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 284.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Remove Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title         0\n",
       "overview      1\n",
       "genres        1\n",
       "popularity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title         0\n",
       "overview      0\n",
       "genres        0\n",
       "popularity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null Values\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Remove Duplicates Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate Values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removed Duplicate\n",
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Framed in the 1940s for the double murder of his wife and her lover, upstanding banker Andy Dufresne begins a new life at the Shawshank prison, where he puts his accounting skills to work for an amoral warden. During his long stretch in prison, Dufresne comes to be admired by the other inmates -- including an older prisoner named Red -- for his integrity and unquenchable sense of hope.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overview'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing\n",
    "df['title'] = df['title'].str.lower()\n",
    "df['overview'] = df['overview'].str.lower()\n",
    "df['genres'] = df['genres'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drama, crime'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Whitespace\n",
    "df['title'] = df['title'].str.strip()\n",
    "df['overview'] = df['overview'].str.strip()\n",
    "df['genres'] = df['genres'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'framed in the 1940s for the double murder of his wife and her lover, upstanding banker andy dufresne begins a new life at the shawshank prison, where he puts his accounting skills to work for an amoral warden. during his long stretch in prison, dufresne comes to be admired by the other inmates -- including an older prisoner named red -- for his integrity and unquenchable sense of hope.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overview'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Remove HTML Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HTML tags\n",
    "df['title'] = df['title'].str.replace('<.*?>','')\n",
    "df['overview'] = df['overview'].str.replace('<.*?>','')\n",
    "df['genres'] = df['genres'].str.replace('<.*?>','')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URL \n",
    "df['title'] = df['title'].str.replace('https?://\\S+|www\\.\\S+','')\n",
    "df['overview'] = df['overview'].str.replace('https?://\\S+|www\\.\\S+','')\n",
    "df['genres'] = df['genres'].str.replace('https?://\\S+|www\\.\\S+','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Punctuation\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans(\"\", \"\", string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].str.translate(translator)\n",
    "df['overview'] = df['overview'].str.translate(translator)\n",
    "df['genres'] = df['genres'].str.translate(translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Chat word treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat word treatment\n",
    "def remove_abb(data):\n",
    "    data = re.sub(r\"he's\", \"he is\", data)\n",
    "    data = re.sub(r\"there's\", \"there is\", data)\n",
    "    data = re.sub(r\"We're\", \"We are\", data)\n",
    "    data = re.sub(r\"That's\", \"That is\", data)\n",
    "    data = re.sub(r\"won't\", \"will not\", data)\n",
    "    data = re.sub(r\"they're\", \"they are\", data)\n",
    "    data = re.sub(r\"Can't\", \"Cannot\", data)\n",
    "    data = re.sub(r\"wasn't\", \"was not\", data)\n",
    "    data = re.sub(r\"don\\x89Ûªt\", \"do not\", data)\n",
    "    data= re.sub(r\"aren't\", \"are not\", data)\n",
    "    data = re.sub(r\"isn't\", \"is not\", data)\n",
    "    data = re.sub(r\"What's\", \"What is\", data)\n",
    "    data = re.sub(r\"haven't\", \"have not\", data)\n",
    "    data = re.sub(r\"hasn't\", \"has not\", data)\n",
    "    data = re.sub(r\"There's\", \"There is\", data)\n",
    "    data = re.sub(r\"He's\", \"He is\", data)\n",
    "    data = re.sub(r\"It's\", \"It is\", data)\n",
    "    data = re.sub(r\"You're\", \"You are\", data)\n",
    "    data = re.sub(r\"I'M\", \"I am\", data)\n",
    "    data = re.sub(r\"shouldn't\", \"should not\", data)\n",
    "    data = re.sub(r\"wouldn't\", \"would not\", data)\n",
    "    data = re.sub(r\"i'm\", \"I am\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªm\", \"I am\", data)\n",
    "    data = re.sub(r\"I'm\", \"I am\", data)\n",
    "    data = re.sub(r\"Isn't\", \"is not\", data)\n",
    "    data = re.sub(r\"Here's\", \"Here is\", data)\n",
    "    data = re.sub(r\"you've\", \"you have\", data)\n",
    "    data = re.sub(r\"you\\x89Ûªve\", \"you have\", data)\n",
    "    data = re.sub(r\"we're\", \"we are\", data)\n",
    "    data = re.sub(r\"what's\", \"what is\", data)\n",
    "    data = re.sub(r\"couldn't\", \"could not\", data)\n",
    "    data = re.sub(r\"we've\", \"we have\", data)\n",
    "    data = re.sub(r\"it\\x89Ûªs\", \"it is\", data)\n",
    "    data = re.sub(r\"doesn\\x89Ûªt\", \"does not\", data)\n",
    "    data = re.sub(r\"It\\x89Ûªs\", \"It is\", data)\n",
    "    data = re.sub(r\"Here\\x89Ûªs\", \"Here is\", data)\n",
    "    data = re.sub(r\"who's\", \"who is\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªve\", \"I have\", data)\n",
    "    data = re.sub(r\"y'all\", \"you all\", data)\n",
    "    data = re.sub(r\"can\\x89Ûªt\", \"cannot\", data)\n",
    "    data = re.sub(r\"would've\", \"would have\", data)\n",
    "    data = re.sub(r\"it'll\", \"it will\", data)\n",
    "    data = re.sub(r\"we'll\", \"we will\", data)\n",
    "    data = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", data)\n",
    "    data = re.sub(r\"We've\", \"We have\", data)\n",
    "    data = re.sub(r\"he'll\", \"he will\", data)\n",
    "    data = re.sub(r\"Y'all\", \"You all\", data)\n",
    "    data = re.sub(r\"Weren't\", \"Were not\", data)\n",
    "    data = re.sub(r\"Didn't\", \"Did not\", data)\n",
    "    data = re.sub(r\"they'll\", \"they will\", data)\n",
    "    data = re.sub(r\"they'd\", \"they would\", data)\n",
    "    data = re.sub(r\"DON'T\", \"DO NOT\", data)\n",
    "    data = re.sub(r\"That\\x89Ûªs\", \"That is\", data)\n",
    "    data = re.sub(r\"they've\", \"they have\", data)\n",
    "    data = re.sub(r\"i'd\", \"I would\", data)\n",
    "    data = re.sub(r\"should've\", \"should have\", data)\n",
    "    data = re.sub(r\"You\\x89Ûªre\", \"You are\", data)\n",
    "    data = re.sub(r\"where's\", \"where is\", data)\n",
    "    data = re.sub(r\"Don\\x89Ûªt\", \"Do not\", data)\n",
    "    data = re.sub(r\"we'd\", \"we would\", data)\n",
    "    data = re.sub(r\"i'll\", \"I will\", data)\n",
    "    data = re.sub(r\"weren't\", \"were not\", data)\n",
    "    data = re.sub(r\"They're\", \"They are\", data)\n",
    "    data = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", data)\n",
    "    data = re.sub(r\"you\\x89Ûªll\", \"you will\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªd\", \"I would\", data)\n",
    "    data = re.sub(r\"let's\", \"let us\", data)\n",
    "    data = re.sub(r\"it's\", \"it is\", data)\n",
    "    data = re.sub(r\"can't\", \"cannot\", data)\n",
    "    data = re.sub(r\"don't\", \"do not\", data)\n",
    "    data = re.sub(r\"you're\", \"you are\", data)\n",
    "    data = re.sub(r\"i've\", \"I have\", data)\n",
    "    data = re.sub(r\"that's\", \"that is\", data)\n",
    "    data = re.sub(r\"i'll\", \"I will\", data)\n",
    "    data = re.sub(r\"doesn't\", \"does not\",data)\n",
    "    data = re.sub(r\"i'd\", \"I would\", data)\n",
    "    data = re.sub(r\"didn't\", \"did not\", data)\n",
    "    data = re.sub(r\"ain't\", \"am not\", data)\n",
    "    data = re.sub(r\"you'll\", \"you will\", data)\n",
    "    data = re.sub(r\"I've\", \"I have\", data)\n",
    "    data = re.sub(r\"Don't\", \"do not\", data)\n",
    "    data = re.sub(r\"I'll\", \"I will\", data)\n",
    "    data = re.sub(r\"I'd\", \"I would\", data)\n",
    "    data = re.sub(r\"Let's\", \"Let us\", data)\n",
    "    data = re.sub(r\"you'd\", \"You would\", data)\n",
    "    data = re.sub(r\"It's\", \"It is\", data)\n",
    "    data = re.sub(r\"Ain't\", \"am not\", data)\n",
    "    data = re.sub(r\"Haven't\", \"Have not\", data)\n",
    "    data = re.sub(r\"Could've\", \"Could have\", data)\n",
    "    data = re.sub(r\"youve\", \"you have\", data)  \n",
    "    data = re.sub(r\"donå«t\", \"do not\", data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overview'] = df['overview'].apply(remove_abb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the shawshank redemption</td>\n",
       "      <td>framed in the 1940s for the double murder of h...</td>\n",
       "      <td>drama crime</td>\n",
       "      <td>146.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the godfather</td>\n",
       "      <td>spanning the years 1945 to 1955 a chronicle of...</td>\n",
       "      <td>drama crime</td>\n",
       "      <td>121.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the godfather part ii</td>\n",
       "      <td>in the continuing saga of the corleone crime f...</td>\n",
       "      <td>drama crime</td>\n",
       "      <td>82.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schindlers list</td>\n",
       "      <td>the true story of how businessman oskar schind...</td>\n",
       "      <td>drama history war</td>\n",
       "      <td>66.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 angry men</td>\n",
       "      <td>the defense and the prosecution have rested an...</td>\n",
       "      <td>drama</td>\n",
       "      <td>59.231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  the shawshank redemption   \n",
       "1             the godfather   \n",
       "2     the godfather part ii   \n",
       "3           schindlers list   \n",
       "4              12 angry men   \n",
       "\n",
       "                                            overview             genres  \\\n",
       "0  framed in the 1940s for the double murder of h...        drama crime   \n",
       "1  spanning the years 1945 to 1955 a chronicle of...        drama crime   \n",
       "2  in the continuing saga of the corleone crime f...        drama crime   \n",
       "3  the true story of how businessman oskar schind...  drama history war   \n",
       "4  the defense and the prosecution have rested an...              drama   \n",
       "\n",
       "   popularity  \n",
       "0     146.944  \n",
       "1     121.870  \n",
       "2      82.270  \n",
       "3      66.670  \n",
       "4      59.231  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Spell Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to et re'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spell Correction\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Example of textblob\n",
    "text = 'I want to et rce'\n",
    "TextBlob(text).correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_correction(text):\n",
    "    return TextBlob(text).correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['overview'] = df['overview'].apply(spelling_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [word for word in word_tokenize(text) if word not in stopwords.words('english')]\n",
    "    return ' '.join(words).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(remove_stopwords)\n",
    "df['overview'] = df['overview'].apply(remove_stopwords)\n",
    "df['genres'] = df['genres'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       framed 1940s double murder wife lover upstandi...\n",
       "1       spanning years 1945 1955 chronicle fictional i...\n",
       "2       continuing saga corleone crime family young vi...\n",
       "3       true story businessman oskar schindler saved t...\n",
       "4       defense prosecution rested jury filing jury ro...\n",
       "                              ...                        \n",
       "9096    filmmaking team behind hits scary movie date m...\n",
       "9097    year 3000 man match psychlos greedy manipulati...\n",
       "9098    set island coast techno rave party attracts di...\n",
       "9099    18th birthday goku receives mystical dragonbal...\n",
       "9100    platoon eagles vultures attacks residents smal...\n",
       "Name: overview, Length: 9098, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overview']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Handling Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['😊', '🐍']\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "text = \"I love Python! 😊🐍 #programming\"\n",
    "\n",
    "# Extract emojis\n",
    "emojis = [c for c in text if c in emoji.EMOJI_DATA]\n",
    "print(emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love Python!  #programming\n"
     ]
    }
   ],
   "source": [
    "# Remove Emojis\n",
    "clean_text = ''.join([c for c in text if c not in emoji.EMOJI_DATA])\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love Python! :smiling_face_with_smiling_eyes::snake: #programming'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace emojis with textual representations\n",
    "text_with_replacements = emoji.demojize(text)\n",
    "text_with_replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies</th>\n",
       "      <th>Emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>⛴️🌊❄️💔👫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>🦁👑🎶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>🌍🌳💙👽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>🌑🦇🌆🃏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>🗝️🤝👨⚖️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Movies   Emojis\n",
       "0                   Titanic  ⛴️🌊❄️💔👫\n",
       "1             The Lion King      🦁👑🎶\n",
       "2                    Avatar     🌍🌳💙👽\n",
       "3           The Dark Knight     🌑🦇🌆🃏\n",
       "4  The Shawshank Redemption   🗝️🤝👨⚖️"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply on dataFrame\n",
    "df_emoji = pd.read_csv(os.path.join('dataset','Emoji','Movies_to_Emojis.csv'))\n",
    "df_emoji.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies</th>\n",
       "      <th>Emojis</th>\n",
       "      <th>Emoji to text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>⛴️🌊❄️💔👫</td>\n",
       "      <td>:ferry::water_wave::snowflake::broken_heart::w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>🦁👑🎶</td>\n",
       "      <td>:lion::crown::musical_notes:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>🌍🌳💙👽</td>\n",
       "      <td>:globe_showing_Europe-Africa::deciduous_tree::...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>🌑🦇🌆🃏</td>\n",
       "      <td>:new_moon::bat::cityscape_at_dusk::joker:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>🗝️🤝👨⚖️</td>\n",
       "      <td>:old_key::handshake::man::balance_scale:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Movies   Emojis  \\\n",
       "0                   Titanic  ⛴️🌊❄️💔👫   \n",
       "1             The Lion King      🦁👑🎶   \n",
       "2                    Avatar     🌍🌳💙👽   \n",
       "3           The Dark Knight     🌑🦇🌆🃏   \n",
       "4  The Shawshank Redemption   🗝️🤝👨⚖️   \n",
       "\n",
       "                                       Emoji to text  \n",
       "0  :ferry::water_wave::snowflake::broken_heart::w...  \n",
       "1                       :lion::crown::musical_notes:  \n",
       "2  :globe_showing_Europe-Africa::deciduous_tree::...  \n",
       "3          :new_moon::bat::cityscape_at_dusk::joker:  \n",
       "4           :old_key::handshake::man::balance_scale:  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emoji['Emoji to text'] = df_emoji['Emojis'].apply(emoji.demojize)\n",
    "df_emoji.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'Python', '!', '😊🐍', '#', 'programming']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'Python', '!', '😊', '🐍', '#', 'programming']\n"
     ]
    }
   ],
   "source": [
    "# Spacy Tokenization\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text) \n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization is important.', 'It helps break text into smaller units.', 'Sentences are a common choice for tokenization in NLP.']\n",
      "[['Tokenization', 'is', 'important', '.'], ['It', 'helps', 'break', 'text', 'into', 'smaller', 'units', '.'], ['Sentences', 'are', 'a', 'common', 'choice', 'for', 'tokenization', 'in', 'NLP', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Sentence-wise tokenization\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"Tokenization is important. It helps break text into smaller units. Sentences are a common choice for tokenization in NLP.\"\n",
    "sentences = sent_tokenize(text)\n",
    "sentence_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "print(sentences)\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words ['Stemming', 'is', 'a', 'process', 'of', 'reducing', 'words', 'to', 'their', 'base', 'form', '.']\n",
      "Stemmed words ['stem', 'is', 'a', 'process', 'of', 'reduc', 'word', 'to', 'their', 'base', 'form', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "text = \"Stemming is a process of reducing words to their base form.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
    "\n",
    "print('Original words',words)\n",
    "print('Stemmed words',stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words ['Lemmatization', 'is', 'a', 'process', 'of', 'reducing', 'words', 'to', 'their', 'base', 'form', '.']\n",
      "Stemmed words ['Lemmatization', 'be', 'a', 'process', 'of', 'reduce', 'word', 'to', 'their', 'base', 'form', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "text = \"Lemmatization is a process of reducing words to their base form.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "\n",
    "print('Original words',words)\n",
    "print('Stemmed words',lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
