{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer encoding simplernn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['go india',\n",
    "\t\t'india india',\n",
    "\t\t'hip hip hurray',\n",
    "\t\t'jeetega bhai jeetega india jeetega',\n",
    "\t\t'bharat mata ki jai',\n",
    "\t\t'kohli kohli',\n",
    "\t\t'sachin sachin',\n",
    "\t\t'dhoni dhoni',\n",
    "\t\t'modi ji ki jai',\n",
    "\t\t'inquilab zindabad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the document\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<nothing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<nothing>': 1,\n",
       " 'india': 2,\n",
       " 'jeetega': 3,\n",
       " 'hip': 4,\n",
       " 'ki': 5,\n",
       " 'jai': 6,\n",
       " 'kohli': 7,\n",
       " 'sachin': 8,\n",
       " 'dhoni': 9,\n",
       " 'go': 10,\n",
       " 'hurray': 11,\n",
       " 'bhai': 12,\n",
       " 'bharat': 13,\n",
       " 'mata': 14,\n",
       " 'modi': 15,\n",
       " 'ji': 16,\n",
       " 'inquilab': 17,\n",
       " 'zindabad': 18}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index of each word in the document\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('go', 1),\n",
       "             ('india', 4),\n",
       "             ('hip', 2),\n",
       "             ('hurray', 1),\n",
       "             ('jeetega', 3),\n",
       "             ('bhai', 1),\n",
       "             ('bharat', 1),\n",
       "             ('mata', 1),\n",
       "             ('ki', 2),\n",
       "             ('jai', 2),\n",
       "             ('kohli', 2),\n",
       "             ('sachin', 2),\n",
       "             ('dhoni', 2),\n",
       "             ('modi', 1),\n",
       "             ('ji', 1),\n",
       "             ('inquilab', 1),\n",
       "             ('zindabad', 1)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count exach word occurrences in the document\n",
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of sentences in the document\n",
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 2],\n",
       " [2, 2],\n",
       " [4, 4, 11],\n",
       " [3, 12, 3, 2, 3],\n",
       " [13, 14, 5, 6],\n",
       " [7, 7],\n",
       " [8, 8],\n",
       " [9, 9],\n",
       " [15, 16, 5, 6],\n",
       " [17, 18]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence --> insert index on each word in the sentence\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  2,  0,  0,  0],\n",
       "       [ 2,  2,  0,  0,  0],\n",
       "       [ 4,  4, 11,  0,  0],\n",
       "       [ 3, 12,  3,  2,  3],\n",
       "       [13, 14,  5,  6,  0],\n",
       "       [ 7,  7,  0,  0,  0],\n",
       "       [ 8,  8,  0,  0,  0],\n",
       "       [ 9,  9,  0,  0,  0],\n",
       "       [15, 16,  5,  6,  0],\n",
       "       [17, 18,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add padding to equalize the length of the sentences\n",
    "sequences = pad_sequences(sequences, padding='post')\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemet Ingeger encoding and sentiment analysis on Ibdb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 12:10:55.751436: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-15 12:10:55.809917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-15 12:10:55.809973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-15 12:10:55.811550: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-15 12:10:55.820527: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-15 12:10:55.821525: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-15 12:10:57.130479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ibdb dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "# Shape is not same\n",
    "print(len(X_train[0]))\n",
    "print(len(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=2000)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))\n",
    "print(len(X_train[1]))\n",
    "\n",
    "print(len(X_test[0]))\n",
    "print(len(X_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 32)                1088      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1121 (4.38 KB)\n",
      "Trainable params: 1121 (4.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Make model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SimpleRNN(32, input_shape=(2000,1), return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 11:45:25.778052: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 200000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.5044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 11:46:59.531277: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 200000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 119s 151ms/step - loss: 0.6948 - accuracy: 0.5044 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 119s 152ms/step - loss: 0.6939 - accuracy: 0.5029 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 124s 159ms/step - loss: 0.6940 - accuracy: 0.4980 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 118s 151ms/step - loss: 0.6939 - accuracy: 0.4956 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 117s 150ms/step - loss: 0.6938 - accuracy: 0.4968 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 117s 150ms/step - loss: 0.6938 - accuracy: 0.4982 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 118s 151ms/step - loss: 0.6939 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.6942 - accuracy: 0.4966 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 119s 152ms/step - loss: 0.6939 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 124s 159ms/step - loss: 0.6940 - accuracy: 0.4997 - val_loss: 0.6935 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7faf31d66650>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['go india',\n",
    "\t\t'india india',\n",
    "\t\t'hip hip hurray',\n",
    "\t\t'jeetega bhai jeetega india jeetega',\n",
    "\t\t'bharat mata ki jai',\n",
    "\t\t'kohli kohli',\n",
    "\t\t'sachin sachin',\n",
    "\t\t'dhoni dhoni',\n",
    "\t\t'modi ji ki jai',\n",
    "\t\t'inquilab zindabad']\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<nothing>')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences = pad_sequences(sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique words/vocabulary\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  2,  0,  0,  0],\n",
       "       [ 2,  2,  0,  0,  0],\n",
       "       [ 4,  4, 11,  0,  0],\n",
       "       [ 3, 12,  3,  2,  3],\n",
       "       [13, 14,  5,  6,  0],\n",
       "       [ 7,  7,  0,  0,  0],\n",
       "       [ 8,  8,  0,  0,  0],\n",
       "       [ 9,  9,  0,  0,  0],\n",
       "       [15, 16,  5,  6,  0],\n",
       "       [17, 18,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 5, 2)              38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38 (152.00 Byte)\n",
      "Trainable params: 38 (152.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=2, input_length=5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa8cc776440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[[-1.0384776e-02 -1.5346445e-02]\n",
      "  [ 2.4144862e-02  8.8497289e-03]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]\n",
      "\n",
      " [[ 2.4144862e-02  8.8497289e-03]\n",
      "  [ 2.4144862e-02  8.8497289e-03]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]\n",
      "\n",
      " [[ 3.3095840e-02  4.0282276e-02]\n",
      "  [ 3.3095840e-02  4.0282276e-02]\n",
      "  [ 1.6763806e-03 -4.0257491e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]\n",
      "\n",
      " [[-1.1828639e-02  5.4417737e-03]\n",
      "  [-8.5482374e-03  1.9831657e-03]\n",
      "  [-1.1828639e-02  5.4417737e-03]\n",
      "  [ 2.4144862e-02  8.8497289e-03]\n",
      "  [-1.1828639e-02  5.4417737e-03]]\n",
      "\n",
      " [[ 4.6200160e-02  4.5745838e-02]\n",
      "  [ 1.0810792e-05 -1.3433218e-02]\n",
      "  [ 9.3613267e-03  1.8563081e-02]\n",
      "  [-3.0542625e-02 -6.1401017e-03]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]\n",
      "\n",
      " [[ 2.2988703e-02 -2.8293861e-02]\n",
      "  [ 2.2988703e-02 -2.8293861e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]\n",
      "\n",
      " [[-1.9873500e-02 -4.0938593e-02]\n",
      "  [-1.9873500e-02 -4.0938593e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]\n",
      "\n",
      " [[ 1.2718741e-02  1.0657132e-02]\n",
      "  [ 1.2718741e-02  1.0657132e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]\n",
      "\n",
      " [[-2.8533472e-02 -4.6680570e-03]\n",
      "  [-2.5425076e-02 -6.4128637e-03]\n",
      "  [ 9.3613267e-03  1.8563081e-02]\n",
      "  [-3.0542625e-02 -6.1401017e-03]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]\n",
      "\n",
      " [[-4.7001328e-02 -4.5227971e-02]\n",
      "  [ 2.8017130e-02  1.5907232e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]\n",
      "  [ 4.8912708e-02  4.8791420e-02]]]\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam','accuracy')\n",
    "pred = model.predict(sequences)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb dataset\n",
    "max_features = 10000  # Number of words to consider as features\n",
    "maxlen = 500  # Cuts off texts after this many words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 500, 32)           320000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322113 (1.23 MB)\n",
      "Trainable params: 322113 (1.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32, input_length=maxlen))\n",
    "model.add(SimpleRNN(32, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 67s 84ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6924 - val_accuracy: 0.5014\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 58s 74ms/step - loss: 0.6870 - accuracy: 0.5202 - val_loss: 0.6911 - val_accuracy: 0.5083\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.6664 - accuracy: 0.5346 - val_loss: 0.6966 - val_accuracy: 0.5071\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.6436 - accuracy: 0.5428 - val_loss: 0.7068 - val_accuracy: 0.5027\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.6385 - accuracy: 0.5448 - val_loss: 0.7190 - val_accuracy: 0.5051\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
